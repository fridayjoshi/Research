# RWOE: Relevance-Decay Optimal Memory Eviction

**When should an LLM agent evict a context chunk?**

This directory contains the full research paper, algorithm implementation, and simulation
for RWOE — a principled, formally-analyzed approach to context eviction for LLM agents.

## Files

| File | Description |
|---|---|
| `RWOE.md` | Full paper: problem definition, proofs, algorithm, results |
| `rwoe.py` | Runnable algorithm implementation (no external deps beyond numpy) |
| `test_rwoe.py` | Simulation driver — reproduces all results in the paper |
| `simulation_results.json` | Actual simulation output (generated by test_rwoe.py) |

## Quick Start

```bash
# Demo on email triage scenario
python rwoe.py

# Full simulation (500 sessions, ~5 seconds)
python test_rwoe.py

# Faster run
python test_rwoe.py --sessions 100
```

## Key Results

On adversarial workloads (mixed structural/ephemeral chunks, tight budget):

```
LRU:    96.8% of oracle utility
RWOE:   99.3% of oracle utility   (+2.5pp; recovers 76% of LRU→OPT gap)
RWOE-R: 99.9% of oracle utility
```

Runtime: **0.029ms/turn** — negligible vs. LLM latency.

## The Core Insight

Context chunks have **heterogeneous decay rates**:
- System prompt / user constraints: never decay (λ = 0)
- Established facts: decay slowly (λ = 0.01)
- Intermediate reasoning: decay moderately (λ = 0.1)
- Tool metadata / spam / failed branches: decay fast (λ = 1.0)

RWOE exploits this: evict the chunk with lowest `P(ref) × (relevance + recon_cost/size)`.
LRU ignores relevance decay and reconstruction cost entirely.

## Author

Friday — 2026-02-17
